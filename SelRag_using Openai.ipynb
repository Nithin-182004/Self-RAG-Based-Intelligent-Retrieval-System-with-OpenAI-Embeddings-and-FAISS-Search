{
  "metadata": {
    "kernelspec": {
      "name": "xpython",
      "display_name": "Python 3.13 (XPython)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "68566561-6044-40c4-b4dd-f2849328cb32",
      "cell_type": "code",
      "source": "import os\nimport openai\nimport numpy as np\n\n# STEP 1: Set API Key\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\nif not openai.api_key:\n    import getpass\n    openai.api_key = getpass.getpass(\"Enter your OpenAI API Key: \")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e928d848-c591-4626-8fda-05c075a72f27",
      "cell_type": "code",
      "source": "# STEP 2: Load local .txt files from a folder\ndef load_documents_from_folder(folder_path):\n    documents = []\n    for filename in os.listdir(folder_path):\n        if filename.endswith(\".txt\"):\n            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n                documents.append(f.read())\n    return documents\n\nfolder_path = \"./docs\"  \ndocs_list = load_documents_from_folder(folder_path)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4cec924a-9830-43a8-8dd7-8154dfba5439",
      "cell_type": "code",
      "source": "# STEP 3: Chunk each document\ndef split_text(text, chunk_size=1000):\n    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n\nchunks = []\nfor doc in docs_list:\n    chunks.extend(split_text(doc))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a7503b35-1ffe-4fe1-a2ea-c0becd43ec6b",
      "cell_type": "code",
      "source": "# STEP 4: Generate embeddings for each chunk\ndef get_embedding(text):\n    response = openai.Embedding.create(\n        model=\"text-embedding-3-small\",\n        input=text\n    )\n    return response[\"data\"][0][\"embedding\"]\n\nchunk_embeddings = [get_embedding(chunk) for chunk in chunks]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7c5fd215-afee-4079-80ec-c1b3403d54c1",
      "cell_type": "code",
      "source": "# --- STEP 5: Build FAISS index ---\nindex = faiss.IndexFlatL2(dimension)\nindex.add(np.array(embeddings).astype(\"float32\"))  ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "03b1faaf-2af4-4f56-9db8-2199f17c554e",
      "cell_type": "code",
      "source": "# --- STEP 6: Embed user question and search ---\nquestion = \"agent memory\"\nquestion_embedding = np.array(get_embedding(question)).astype(\"float32\")\ntop_k = 3\ndistances, indices = index.search(np.array([question_embedding]), top_k)\n\n# --- STEP 7: Retrieve top documents ---\nretrieved_chunks = [chunks[i] for i in indices[0]]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7d5887f7-ed85-42f4-ba7f-1b4f17e455b6",
      "cell_type": "code",
      "source": "# --- STEP 8: Grade relevance using GPT\ndef grade_relevance(document, question):\n    system_prompt = \"\"\"You are a grader checking if a document is relevant to the user's question.\nIf the document contains keyword(s) or semantic meaning related to the question, say 'yes'. Else, say 'no'.\"\"\"\n    \n    response = openai.ChatCompletion.create(\n        model=\"gpt-4o\",\n        temperature=0,\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": f\"Document:\\n{document}\\n\\nQuestion: {question}\"}\n        ]\n    )\n    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n\nprint(\"\\n--- Relevance Grading ---\")\nfor i, chunk in enumerate(retrieved_chunks):\n    print(f\"\\nChunk {i+1}:\\n{grade_relevance(chunk, question)}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "af220750-b834-4318-8d4d-93e68c090b8a",
      "cell_type": "code",
      "source": "# --- STEP 9: Answer generation using GPT ---\ndef generate_answer(question, context_chunks):\n    context = \"\\n\\n\".join(context_chunks)\n    prompt = f\"\"\"You are a helpful assistant. Use the following context to answer the user's question.\n\nContext:\n{context}\n\nQuestion: {question}\nAnswer:\"\"\"\n    response = openai.ChatCompletion.create(\n        model=\"gpt-3.5-turbo\",\n        temperature=0,\n        messages=[{\"role\": \"user\", \"content\": prompt}]\n    )\n    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n\nprint(\"\\n--- Final Answer ---\")\nanswer = generate_answer(question, retrieved_chunks)\nprint(answer)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5ab84d02-0787-4de7-a275-1c93c76591ed",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}